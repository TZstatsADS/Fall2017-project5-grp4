{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X,sr = librosa.load(fp)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n",
    "    features, labels = np.empty((0,193)), np.empty(0) #193 #63\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "              mfccs, chroma, mel,contrast,tonnetz = extract_feature(fn)\n",
    "            except Exception as e:\n",
    "              print(\"Error encountered while parsing file: \", fn)\n",
    "              continue\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            features = np.vstack([features,ext_features])\n",
    "            labels = np.append(labels, label+1) #fn.split('/')[2].split('-')[1]\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, \"*.mp3\")):\n",
    "            try:\n",
    "              mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "            except Exception as e:\n",
    "              print(\"Error encountered while parsing file: \", fn)\n",
    "              continue\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            features = np.vstack([features,ext_features])\n",
    "            labels = np.append(labels, label+1) #fn.split('/')[2].split('-')[1]\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 1: Waveplot\",x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        specgram(np.array(f), Fs=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 2: Spectrogram\",x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        D = librosa.logamplitude(np.abs(librosa.stft(f))**2, ref_power=np.max)\n",
    "        librosa.display.specshow(D,x_axis='time' ,y_axis='log')\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 3: Log power spectrogram\",x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sounds = load_sound_files(sound_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sound_file_paths = ['UrbanSound/data/1/101729.wav','UrbanSound/data/2/107090.wav']\n",
    "raw_sounds = load_sound_files(sound_file_paths)\n",
    "sound_names = [\"air conditioner\",\"car horn\"]\n",
    "\n",
    "raw_sounds = load_sound_files(sound_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_waves(sound_names,raw_sounds)\n",
    "#plot_specgram(sound_names,raw_sounds)\n",
    "#plot_log_power_specgram(sound_names,raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-cc14c281a229>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-cc14c281a229>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    X, sample_rate = librosa.load(''./UrbanSound/data/1/101729.wav')\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X, sample_rate = librosa.load(''./UrbanSound/data/1/101729.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfccs,chroma,mel,contrast,tonnetz = extract_feature('./try/1/13230.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,) (12,) (128,) (7,) (6,)\n"
     ]
    }
   ],
   "source": [
    "print(mfccs.shape,chroma.shape,mel.shape,contrast.shape,tonnetz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from 10 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linhan/anaconda/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  ./UrbanSound/data/6/78651.wav\n"
     ]
    }
   ],
   "source": [
    "features,labels = parse_audio_files('./UrbanSound/data',['1','2','3','4','5','6','7','8','9','10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"features.csv\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"labels.csv\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102, 193)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
